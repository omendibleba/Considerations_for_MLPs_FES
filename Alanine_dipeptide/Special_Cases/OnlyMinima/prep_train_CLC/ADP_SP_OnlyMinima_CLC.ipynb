{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Using gen_ini_full_cv Python Script for Generating Uniformly Distributed Initial Configurations\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The gen_ini_full_cv script is a powerful tool designed to generate uniformly distributed initial configurations in a 2D collective variable space. This tutorial will guide you through the process of using this script effectively.\n",
    "\n",
    "\n",
    "### Usage\n",
    "\n",
    "The initial_config.py script accepts several command-line arguments to customize the generation process. Be sure to habe the the lammps and plumed reference files.\n",
    "\n",
    "Here's a breakdown of the available options:\n",
    "\n",
    "    cv1_bin : Number of bins for the first collective variable (Cv_1).\n",
    "    cv1_min : Minimum value of Cv_1.\n",
    "    cv1_max : Maximum value of Cv_1.\n",
    "    cv2_bin : Number of bins for the second collective variable (Cv_2).\n",
    "    cv2_min : Minimum value of Cv_2.\n",
    "    cv2_max : Maximum value of Cv_2.\n",
    "    --plot : Flag to visualize the generated points.\n",
    "\n",
    "To execute the script, open a terminal or command prompt and run the following command:\n",
    "\n",
    "python initial_configs.py 224 -3.14 3.14 224 -3.14 3.14\n",
    "\n",
    "This will generate 50176 initial conviguration equally distributed between -pi to pi in both dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection on initial configurations\n",
    "\n",
    "This step consist of running a simulation with each of the created initial configuration from each step. THis is achieved using the 'run_cv_config_select_1.py' script. Thi sscript will recreate the referece array from the CVs so make sure to modify the bins and min-max values for each arra, so they mathc the values used in the previous step. Each simulation is ran for 1 ns while the phi and psi values are   (Cvs) are colected, at the end of the simulation the CV values are compared to the reference value. If the error is less that 0.3%, the inthex of the row with the smalles error is stored and the code, continues to the next iterarion. If the error is more than 0.3%, the seed number of the velocity in the lammps imput file is changed, and the process is repeated until the value is obtained..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for usage \n",
    "# os.system('python run_cv_config_select_1.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the configurations with the desired CV values has been obtained we will proceed to run single point claculations of said configurationsto generate the ADP_OnlyMinima training data set. FOr storage purposes the productions_runs folder has been shared as a zip file. \n",
    "\n",
    "Now run the lmp_spc_prep.py script to run a single pooint calculation with classical level MD of the runs which had sampled CV values with a percent difference lower than 0.3%.\n",
    "\n",
    "Run the 'selected_phi_psi.py' to generate a second list of the selected indices. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of relevant files and folders\n",
    "data_folder = './production_runs/'\n",
    "# workig_folder = 'umbrella_'\n",
    "log_file = 'adp_clmd_2ns_umb_' #'log.lammps'\n",
    "forces_file = 'forces.dump'\n",
    "xyz_traj_file = 'traj_nnip.xyz'\n",
    "lmp_spc_folder = './lmp_spc_500Frames/' # Folder were new data files will be saved. LAMMPS spc\n",
    "workig_folder = 'umbrella_'\n",
    "og_data_file = './example.input'\n",
    "lmp_input_file = './input_0.inp'\n",
    "verbose =True\n",
    "indices_file = 'index_pcnt_diff.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the phi and psi values from the file\n",
    "# selected_phi_psi = np.loadtxt('selected_phi_psi.txt')\n",
    "\n",
    "# Load npy file\n",
    "selected_phi_psi = np.load('selected_phi_psi.npy')\n",
    "print(selected_phi_psi.shape)\n",
    "umbrella = selected_phi_psi[:,0]\n",
    "index = selected_phi_psi[:,1]\n",
    "phi = selected_phi_psi[:,2]\n",
    "psi = selected_phi_psi[:,3]\n",
    "\n",
    "## IMPORTANT NOTE: This values represent the the index (frame) per umbrella where the phi-psi combination are closer to the desired value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "import pandas as pd\n",
    "selected_phi_psi = pd.DataFrame(selected_phi_psi, columns=['umbrella', 'index', 'phi', 'psi'])\n",
    "#selected_phi_psi.head()\n",
    "\n",
    "# Delete the rows that have 0.0 in the index,phi,psi columns\n",
    "selected_phi_psi = selected_phi_psi.loc[selected_phi_psi['index'] != 0.0]\n",
    "#selected_phi_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the indices have been selected, we can proceed to select the regions in which we want to take samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selection of points\n",
    "\n",
    "phi_values =  np.rad2deg(selected_phi_psi['phi']) # Replace with actual phi values\n",
    "psi_values =    np.rad2deg(selected_phi_psi['psi']) # Replace with actual psi values\n",
    "\n",
    "# List of user-provided phi and psi values\n",
    "user_values_list = [(-143.66420274551217, 155.47320410490312),\n",
    "(-79.67265047518481, 59.00798175598632),\n",
    "(60.34846884899679, -41.90421892816417),\n",
    "(-84.7412882787751, 136.65906499429877)]  # Add more values as needed\n",
    "\n",
    "# Number of points to select\n",
    "m = 125   ## for 500 samples\n",
    "#m = 250  ## for 1000 samples\n",
    "#m = 625  ###for 2500 samples \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get euclidean distance between available points and selected centers\n",
    "indexes =[]\n",
    "\n",
    "for user_values in user_values_list[:]:\n",
    "    user_phi, user_psi = user_values\n",
    "    print(f\"User input. phi = {user_phi}, psi = {user_psi}\" )\n",
    "\n",
    "    # Calculate the distance between the user-provided phi and psi values and the phi and psi values in the dataset\n",
    "    distances = np.sqrt((phi_values - user_phi)**2 + (psi_values - user_psi)**2)\n",
    "    print(f\"Shape of distances array {distances.shape}\")\n",
    "\n",
    "    # Get indices of m closest points\n",
    "    indices = np.argsort(distances)[:m] \n",
    "    print(f\"Shape of indices array {indices.shape}\")\n",
    "    print(indices)\n",
    "\n",
    "    # append indices to list\n",
    "    indexes.append(indices)\n",
    "\n",
    "# Convert list to numpy array\n",
    "indexes = np.array(indexes).T\n",
    "#reshape array to 1D\n",
    "indexes = indexes.reshape(-1)\n",
    "print(f\"Shape of indexes array {indexes.shape}\")\n",
    "\n",
    "euclid_selected_phi_psi = selected_phi_psi.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the phi vs psi of the selected points\n",
    "\n",
    "plt.scatter(np.rad2deg(euclid_selected_phi_psi['phi']),np.rad2deg(euclid_selected_phi_psi['psi']),marker='o',c='r',s=10)\n",
    "plt.xlabel('Phi',fontsize=14)\n",
    "plt.ylabel('Psi',fontsize=14)\n",
    "plt.title(f'{len(user_values_list)*m} Selected Points')\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "# plt.xlim(-np.pi,np.pi)\n",
    "# plt.ylim(-np.pi,np.pi)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Code to select coordiantes of configurations and create files for lammps spc \n",
    "\n",
    "# grab the values of the umbrella and index columns in arrays \n",
    "umbrellas = euclid_selected_phi_psi['umbrella'].values\n",
    "index = euclid_selected_phi_psi['index'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create folder to store the new data files\n",
    "\n",
    "# ## Check if the lmp_spc_folder exits, if not create it\n",
    "# if not os.path.exists(lmp_spc_folder):\n",
    "#     os.makedirs(lmp_spc_folder)\n",
    "\n",
    "#     #i = 1\n",
    "\n",
    "# # Loop over indices from selected \n",
    "# for i,umbrella in enumerate(umbrellas[:5]):\n",
    "#     print(f'\\n\\nProcessing Umbrella: {int(umbrella)}')\n",
    "\n",
    "#     # 1. Determine the working directory and the index of interest for each umbrella.\n",
    "#     working_dir = f'{data_folder}umbrella_{int(umbrella)}/'\n",
    "#     print(f'Working directory: {working_dir}')\n",
    "#     print(f'Index with smallest error is {int(index[i])}')\n",
    "\n",
    "#     ## 2. Determine the working xyz file.\n",
    "#     working_xyz_file = working_dir + xyz_traj_file\n",
    "#     print(f'Working xyz file: {working_xyz_file}')\n",
    "\n",
    "#     # Read the coordinates from the xyz file\n",
    "#     xyz_traj_dict = read_xyz_traj(working_xyz_file)\n",
    "\n",
    "#     # Extract the coordinates from the dictionary\n",
    "#     xyz_coordinates = xyz_cords_array(xyz_traj_dict,int(index[i]))   #xyz_traj_dict['frames'][indices[i]]\n",
    "\n",
    "#     # Substitute the coordinates in the lammps data file\n",
    "#     lmp_data_subs_coord(xyz_coordinates,og_data_file,f'{lmp_spc_folder}frame_{int(umbrella)}.data',LOUD=False)\n",
    "#     # REname the filename in the read_data command in the lammps input file\n",
    "#     change_data_file_name(f'{lmp_input_file}',f'frame_{int(umbrella)}.data',LOUD=False)\n",
    "\n",
    "#     #3. Create directory to store lammps data and input files.\n",
    "#     os.makedirs(lmp_spc_folder+f'umbrella_{int(umbrella)}', exist_ok=True)\n",
    "\n",
    "#     print(f'Created directory: {lmp_spc_folder}umbrella_{int(umbrella)}')\n",
    "\n",
    "#     # move the data file to the folder\n",
    "#     os.system(f'mv {lmp_spc_folder}frame_{int(umbrella)}.data {lmp_spc_folder}/umbrella_{int(umbrella)}/')\n",
    "\n",
    "#     # Copy the input file to the folder\n",
    "#     os.system(f'cp {lmp_input_file} ./plumed.dat {lmp_spc_folder}/umbrella_{int(umbrella)}/')\n",
    "\n",
    "# print(f'\\n\\nAll Done! Thank you!!\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
